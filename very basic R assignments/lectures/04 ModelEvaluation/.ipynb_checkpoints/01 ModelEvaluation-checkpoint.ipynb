{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Evaluation and its generell Problems\n",
    "\n",
    "* Author: Oliver Kretzschmar\n",
    "* Last Update: 2019-05-04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take a look to the video: [Using R in Azure Machine Learning](https://www.youtube.com/watch?v=2f6uY2wpGiQ)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References and our preferred Literature we use in the Lectures of Machine Learning\n",
    "\n",
    "### Books\n",
    "\n",
    "* [AC18] Allaire J., Chollet F.: Deep Learning with R, Manning, 2018 <font color=red>(\\*)</font><font color=black>\n",
    "\n",
    "* [AE16] Alpaydin, E.: Machine Learning, The MIT Press, 2016\n",
    "\n",
    "* [AGC17] Aggarwal C.: Outlier Analysis, Springer, 2nd ed. 2017\n",
    "\n",
    "* [BEP10] Backhaus K., Erichson B.E., Plinke W., Weiber R.: Multivariate Analysemethoden:\tEine anwendungsorientierte Einführung, Springer-Verlag, 13.Auflage, 2010 <font color=red>(\\*)</font><font color=black>\n",
    "\n",
    "* [BEP13] Backhaus K., Erichson B.E., Weiber R.: Fortgeschrittene Multivariate Analysemethoden: Eine anwendungsorientierte Einführung, Springer-Gabler, 2.Auflage, 2013 <font color=red>(\\*)</font><font color=black>\n",
    "\n",
    "* [CM15] Chapman C.N., McDonnell Feit E.: R for Marketing Research and Analytics, Springer, 2015\n",
    "\n",
    "* [GBC17] Goodfellow I., Bengio Y., Courville A.: Deep Learning, The MIT Press, 2017\n",
    "\n",
    "* [GIE03] Guyon I., Elisseeff A.: An Introduction to Variable and Feature Selection, Journal of Machine Learning Research 3 (2003)\n",
    "\n",
    "* [HJW17] Hastie T., James G., Witten D., Tibshirani R.: An Introduction to Statistical Learning, Springer, 2017, Online: http://www-bcf.usc.edu/~gareth/ISL/index.html, Youtube: https://www.dataschool.io/15-hours-of-expert-machine-learning-videos/ <font color=red>(\\*)</font><font color=black>\n",
    "\n",
    "* [HTF17] Hastie T., Tibshirani R., Friedman J.: The Elements of Statistical Learning, Springer, 2017, Online: https://web.stanford.edu/~hastie/ElemStatLearn/\n",
    "\n",
    "* [KM18] Kuhn M., Johnson K.: Applied Predictive Modeling, Springer, 1st ed. 2013, 2st ed. 2018 <font color=red>(\\*)</font><font color=black>\n",
    "\n",
    "* [KR15] Kabacoff R., R in Action: Data Analysis and Graphics with R , Manning, 2nd edition, Online: www.statmethods.net\n",
    "\n",
    "* [RM18] Rokach L., Maimon O.: Data Mining With Decision Trees: Theory And Applications, Wspc, 2nd ed. 2014\n",
    "\n",
    "* [WD17] Wollschläger D.: Grundlagen der Datenanalyse mit R, Springer Spektrum, 2017\n",
    "\n",
    "* [WH19] Wickham H.: Advanced R, CRC Press Inc, 2019, Online: http://adv-r.had.co.nz\n",
    "\n",
    "* [WH17] Wickham H., Grolemund G.: R for Data Science, O'Reilly, 2017, Online: https://r4ds.had.co.nz <font color=red>(\\*)</font><font color=black>\n",
    "\n",
    "* [ZC18] Zheng A., Casari A.: Feature Engineering for Machine Learning Models: Principles and Techniques for Data Scientists, O'Reilly, 2018\n",
    "\n",
    "The books indicated with <font color=red>(\\*)</font><font color=black> are the main references of this lecture and will not therefore always referenced. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Links\n",
    "\n",
    "* [BM17] Bärtl M.: Statistik Schritt für Schritt (Videos), Youtube: https://www.youtube.com/channel/UCtBEklAtHHji2V1TsaTzZXw (simple and good introduction to statistic fundamentals)\n",
    "\n",
    "* [CLO09] Chen L., Ling L., Özsu Tamer M.: Curse of Dimensionality. Springer US, 2009 - https://doi.org/10.1007/978-0-387-39940-9_133)\n",
    "\n",
    "* [FSW19] Feature Selection, https://en.wikipedia.org/wiki/Feature_selection, download 05/2018\n",
    "\n",
    "* [HFR19] Harrell F.: Problems Caused by Categorizing Continuous Variables, http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous, download 03/2019\n",
    "\n",
    "* [JHS18] Sarmer J.: Different Machine Learning and Statistic Videos, Youtube: https://www.youtube.com/user/joshstarmer/videos (good explanations including mathematic)\n",
    "\n",
    "* [KJK19] Kuhn M., Johnson K.: Feature Engineering and Selection: A Practical Approach for Predictive Models, http://www.feat.engineering/index.html, not yet ready at 06/2019\n",
    "\n",
    "* [IFS16] Introduction to Feature Selection methods, https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/, download 01/2019\n",
    "\n",
    "* [LIMT18] Manually calculate a p-value, https://support.minitab.com/en-us/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/manually-calculate-a-p-value/, download 03/2019\n",
    "\n",
    "* [REF19] Rencberoglu E.: Fundamental Techniques of Feature Engineering for Machine Learning, https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114, download 04/2019\n",
    "\n",
    "* [SKN18] Skewness and Kurtosis, https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa, download 06/2018\n",
    "\n",
    "* [SLR19] Simple Linear Regression, https://en.wikipedia.org/wiki/Simple_linear_regression, download 04/2019\n",
    "\n",
    "* [MAT18] Machine Learning Tips, https://github.com/afshinea/stanford-cs-229-machine-learning/raw/master/en/cheatsheet-machine-learning-tips-and-tricks.pdf, download 10/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Considerations of Machine Learning\n",
    "\n",
    "Look at the our equation:\n",
    "\n",
    "$$\\hat{Y} = \\hat{f}(X)$$\n",
    "\n",
    "Mostly a set of inputs $X$ are available. Output $Y$ cannoat easily obtained, so our prediction of $Y$ is $\\hat{Y}$ by a machine learning model. $\\hat{f}$ is our estimate of $f$ and it is our main goal in machine learning to find the best $\\hat{f}$ with acceptable costs.\n",
    "\n",
    "Because there is no ideal perfect model, we have to measure the quality of fit. How can we do this? We will discuss some concepts and quality criterias.\n",
    "\n",
    "`Keep in mind:` Not all of the discussed criterias fit all model algorithm, but they are a good base point of discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean Squared Error (MSE) for Regression\n",
    "\n",
    "`Remember:` In many Machine Learning context you have to minimize (rarely maximize) a so called **loss-function**, which is mostly for a single training example, or a **cost-function**, which is over the entire training set. Sometimes it is also used in the same manner. Both are used to get best fit for the model. **Best fit of model** means that the differences between the true observed value and the predicted values are small. The loss-function measures how close the predicted values are to their corresponding true observed values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One basic *loss-function* is MSE:\n",
    "\n",
    "$$MSE = \\frac{1}{N} {\\sum\\limits_{i=1}^{N}(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "we take the average over all observations, running from $i=1$ to $N$, where $y_i$ is the real observed response of the $i^{th}$ observation and $\\hat{y}_i$ is our predicted response value of the $i^{th}$ observation.\n",
    "\n",
    "`Pay attention:` The *input* variables also known as *predictor* variables or *explanatory* variables or *features*. The *output* variables also known as *response* variables. Also in many cases the predicted and estimated variables will be not signed by a *hat* to simplify, e.g. $\\hat\\beta_0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In a linear regression (here univariate with only one feature (explanatory or input) variable $x$), we try to find a straight line through the values which minimize the MSE.\n",
    "\n",
    "$$ \\hat{y_i} = \\hat{f}(x_i) = b + w_I x_i $$\n",
    "\n",
    "<html><img src=\"../img/MSE1.jpg\", width=800></html>\n",
    "<font size=\"1\">(Imagesource: https://github.com/rasbt/data-science-tutorial/blob/master/code/linear-reqression-leastsquares.ipynb, download 03/2019)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First let us discuss some concepts in conjunction with model evaluation:\n",
    "\n",
    "`Short discussion`: What means 'The truth has to be inside the data'?\n",
    "\n",
    "`Short discussion`: What is the difference between Correlation and Causality? Which role plays domain knowledge?\n",
    "\n",
    "`Short discussion`: What are residuals again?\n",
    "\n",
    "`Short discussion`: As we will see later, we split the data in data sets for training and test and something even more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`Short discussion`: What means Over- and Underfitting?\n",
    "\n",
    "On the left side you see 3 different regression lines (orange, blue, green - ignore black). On the right side you see red the Test MSE (Mean Square Error - discussed below - the smaller the better) and grey the Training MSE. The colored squares represent the different regression lines on left side. Which one is overfitted and which one is the best of them?\n",
    "\n",
    "<html><img src=\"../img/Over1.jpg\"></html>\n",
    "<font size=\"2\">(Imagesource: [HJW17])</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How to avoid overfitting?\n",
    "\n",
    "* Add more relevant data\n",
    "* Use data augmentation\n",
    "* Dimension reduction, e.g. factor analysis\n",
    "* Stop early training the model\n",
    "* Cross-Validation to divide the training data in many different data sets (see later)\n",
    "* Add regularization techniques (see later), e.g. dropouts, L1/L2 regularization\n",
    "* Reduce model complexity, e.g. reduce the number of features and select the relevant ones (see later at Feature Engineering a.s.o.) or using models which do not adjust themselves so much to the training data, e.g. lower-order polynomials \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias-Variance Trade-Off\n",
    "\n",
    "You see the U-shape in the figure above. If the flexibility of a model increases then also MSE increases and the possibility of Overfitting increases. The challenge is to find a good compromise between bias and variance, where bias and variance is low. This is one of most important aspects in machine learning.\n",
    "\n",
    "\n",
    ">\"**Variance** refers to the amount by which $\\hat{f}$ would change if we\n",
    "estimated it using a different training data set. Since the training data\n",
    "are used to fit the statistical learning method, different training data sets\n",
    "will result in a different $\\hat{f}$. But ideally the estimate for f should not vary\n",
    "too much between training sets.\"*\n",
    "\n",
    ">\"**Bias** refers to the error that is introduced by approximating\n",
    "a real-life problem, which may be extremely complicated, by a much\n",
    "simpler model.\"*\n",
    "\n",
    "<font size=\"2\">by Trevor Hastie (Author) An Introduction to Statistical Learning, Springer, 2017</font>\n",
    "\n",
    "<BR>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<html><img src=\"../img/bias-variance1.jpg\", width=900></html>\n",
    "<font size=\"2\">(Imagesource: http://users.stat.umn.edu/~helwig/notes/boot-Notes.pdf - page 47, download 07/2019)</font>\n",
    "\n",
    "You can think about high variance, as you have seen in the graphic above, in the following experiment: We randomly split the data into 2 halves and train a model with the data halves and for high variance we get 2 totally different results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These are two competing aspects for regression and also for classification. In general: the more flexible the model the higher the variance.\n",
    "\n",
    "$${E}(y_0 - \\hat{f}(x_0))^2 = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon)$$\n",
    "\n",
    "E(x) is the expected value of a sample x, so ${E}(y_0 - \\hat{f}(x_0))^2$ is the expected test MSE. $Var(\\hat{f}(x_0))$ is the variance of our model on the test value, $[Bias(\\hat{f}(x_0))]^2$ is the bias of our model on the test value and $Var(\\epsilon)$ is the variance of the error terms. MSE can never lower than $Var(\\epsilon)$, the unavoidable error.\n",
    "\n",
    "`Keep in mind:` Ideal estimators are accurate (small bias) and precise (small variance), but they are not achievable in reality. Accuracy means how close is the predicted value to its true value. Precision is how repeatable a measurement is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compromise between Prediction Accuracy and Model Interpretability\n",
    "\n",
    "If we look at different model approaches, we can see as aboved discussed that some models are very flexible to adapted the real $f$ and some not. \n",
    "\n",
    "`So, why should we not use only the flexible ones, except the disadvantages also discussed above?`\n",
    "\n",
    "The reason is, if we are more interested in `inference` - in opposite to a `prediction`, we want to explain and understand the influence of $X$ to $Y$ and its relationship, our model should be more `interpretable` and that's a characteristic of less flexible and more simple model approaches like e.g. linear regression.\n",
    "\n",
    "We will see many other techniques in the different sections of the machine learning algorithm to evaluate the accuracy of the models - especially in the simple linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Difference between Parametric and Non-Parametric Methods\n",
    "\n",
    "Our consideration is that if there is a relationship between $X$ and $Y$ we can write:\n",
    "\n",
    "$$Y = f(X) + \\epsilon$$\n",
    "\n",
    "$f$ is unknown and $\\epsilon$ is a **random error term** which is independent from $X$. For example, these random errors could be errors in measuring or unknown influencing parameters and so on. \n",
    "\n",
    "`Explanation:` This error is unavoidable in samples. We suppose that these random errors will sum in total to zero (**expected value** is zero - in German: **Erwartungswert** ist Null) because we suppose that we include all sytematical errors in our model. These random errors are not observable, but they are included in the residuals (the difference between the observed and the estimated variable for each observation) as we have already seen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For our context look at the following equation:\n",
    "\n",
    "$$\\hat{Y} = \\hat{f}(X)$$\n",
    "\n",
    "Mostly the set of inputs $X$ are available. Output $Y$ cannot easily obtained, so our prediction of $Y$ is $\\hat{Y}$ by a machine learning model. $\\hat{f}$ is our estimate of $f$ and it is our main goal in machine learning to find the best $\\hat{f}$ with acceptable costs.\n",
    "\n",
    "`Remember`: We model the $\\hat{f}$ for two main reasons: **Interference** and **Prediction**. *Interference* means that we want to know things like how big is the influence of elements of $X$ to $Y$ and which ones of the input variables are important and which ones not and so on. *Prediction* means that we want to know things around the output $Y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parametric Methods \n",
    "\n",
    "In parametric methods we make an assumption of the functional form of $f$ by $\\hat{f}$. In a further step we estimate and calculate the parameters of $\\hat{f}$ by fitting / training the machine learning model. \n",
    "\n",
    "For example: $\\hat{f}$ as a linear regression model with $\\hat{f}(X) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_K x_K$, where $\\beta_0, \\beta_1, \\ldots, \\beta_K$ are the parameters of $\\hat{f}$. $K$ ist the number of input variables.\n",
    "\n",
    "One of the main *disadvantages* of parametric methods is that the model will not optimal match the true form of $f$ - it could be totally different. If we choose more flexible models with more parameters they easily tend to overfit (for \"Overfitting\" see above). The *advantages* are the simpler and more comprehensible interpretation of the results, faster computations and less data necessary.\n",
    "\n",
    "Parametric algorithm are *Linear Regression*, *Logistic Regression, Linear Discriminant Analysis, Simple Neural Networks* and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Non-Parametric Methods \n",
    "\n",
    "In non-parametric methods we do NOT make an assumption of the functional form of $f$ by $\\hat{f}$. By fitting / training the machine learning model we want to find the best estimate of $f$ by $\\hat{f}$ itself. \n",
    "\n",
    "The main *advantage* is that these methods can usually better fit the possible shape of $f$. *Disadvantages* are that we need far more data, they are not so fast to compute and lesser interpretability.\n",
    "\n",
    "Non-parametric algorithms are *k-Nearest Neighbors, Support Vector Machines*, *Decision Trees* and so on.\n",
    "\n",
    "`Short discussion`: What is the difference between structure-exploratory, like Factor analysis and Cluster analysis, and structure-assessing methods, like Regression analysis a.s.o.?\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "664px",
   "left": "0px",
   "right": "1209.67px",
   "top": "125.333px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
