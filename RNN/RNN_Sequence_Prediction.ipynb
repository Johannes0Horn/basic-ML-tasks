{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEQUENCE PREDICTION\n",
    "\n",
    "\n",
    "## Goal\n",
    "\n",
    "Instead of only pitches, we would like to include other aspects of music in our model.\n",
    "These include:\n",
    "* note lengths\n",
    "* Rests\n",
    "This is the only way to create rhythms that make the generated music more interesting.\n",
    "We still limit ourselves to piano midi files, which can contain two tracks due to the notation of the two hands.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "We want to keep the LSTM architecture, because LSTM is ideally suited for sequences.\n",
    "Therefore we thought a lot about the music decoding.\n",
    "Thus, the relevant information should be kept in as few parameters as possible.\n",
    "To do this, we developed the following ideas:\n",
    "\n",
    "### Music rasterization\n",
    "A grid is placed over the music with a resolution greater than the measure (e.g., an eighth note). At each point in this grid, we consider whether a note is struck or held.\n",
    "Thus, note lengths and rests are encoded.\n",
    "\n",
    "* Advantages:\n",
    " * Output is one-dimensional\n",
    " * Low complexity\n",
    "\n",
    "* Disadvantages:\n",
    " * Some notes are not considered in this grid because they are faster (e.g. 1/16 or triplets).\n",
    " * High complexity in pre-processing\n",
    " * Simultaneous notes have to be encoded/decoded as chords\n",
    " \n",
    "This idea was not pursued further due to the high complexity in pre-processing.\n",
    "\n",
    "### Temporal Difference (TD) focused approach\n",
    "\n",
    "The Temporal Difference is the temporal distance between the attack of two successive notes.\n",
    "For this purpose, each Global Offset of all notes in a piece of music was assigned the notes played at that time.\n",
    "Thus, the two piano voices could be combined into one.\n",
    "Since there can be notes of different length in the voices at one time, the length is stored together with each note.\n",
    "An element of this TD-list is coded like this:\n",
    "\n",
    "`[temporal_difference,[[pitch, duration], [pitch, duration], ...]]`\n",
    "\n",
    "The LSTM must receive a uniform input. So the list of pitches must always be the same length. For this reason we have padded the list with empty elements up to a certain length.\n",
    "\n",
    "The attempt to encode music in this form one-hot failed.\n",
    "A vector of this type has a length of about 14,000, which is unsuitable for training.\n",
    "Instead of hot encoding, TD lists could be output directly. However, the floats contained in them are not generated precisely enough and therefore cannot be mapped directly to the target values.\n",
    "\n",
    "Experiments exist on this idea, but they are not presented in this notebook. The reduction of this approach provides the best result and is therefore part of this notebook.\n",
    "\n",
    "### Reduction of the TD-focused approach.\n",
    "\n",
    "The dimension problem of the previous approach is solved by splitting the TD lists.\n",
    "Thus, the new input to the network is to consist of a sequence of lists of 3 elements each. Each of these lists contains the distance to the next note (TD), the duration as well as the pitch.\n",
    "This way, multiple notes can still be played at the same time, since the TD is 0 in this case.\n",
    "\n",
    "Advantages:\n",
    " * Dimensions are greatly reduced compared to the previous approach.\n",
    " * Several notes can be played at the same time and with different lengths\n",
    " * Different distances between notes are possible\n",
    "\n",
    "#### Observations\n",
    "\n",
    "* The parameter `sequence_length` must not be chosen too small. In an experiment with length 24 (v2), continuous loops of the same melodies or patterns occurred, since the training data also repeated at this length.\n",
    "* A larger Sequence Length lengthens the training significantly.\n",
    "* We expect a multidimensional output from the network, matching the input. For this reason, we have added another reshape layer to the architecture.\n",
    "* The longer we train the mesh, the more it adapts to the training data. As a result, you get almost identical training data as output. So the mesh can easily overfit.\n",
    "\n",
    "#### Results\n",
    "* Subfolders results_RNN contain checkpoints of some tests with different parameters. The config.txt describes the configuration for the respective network. In addition, a notebook for the respective test is deposited. Since the training takes extremely long in each case, we could train only few variants.\n",
    "* **Experiment V0**: The network is to be trained with only one piece of music. The goal is to test the basic functionality. By long training and a small dropout rate of 0.1 the loss shall be reduced to a minimum, which means strong overfitting. The output of the network is therefore very similar to the input.\n",
    "* **Experiment V1**: The network was trained on several pieces of music by one composer. The architecture was slightly enlarged and the `sequence_length` was increased to 140.\n",
    "* **Experiment V2**: The network was trained on several pieces of music by one composer. The `sequence_length` was significantly reduced with a value of 24. The result from this experiment sounds best. To avoid repetitive melodies the `sequence_length` can be increased for the generation. \n",
    "* **Experiment V3**: Trained with a mean `sequence_length` of 100 on several pieces of music by a different composer than in the previous trials. The number of parameters that can be learned is decreased.\n",
    "* **Experiment V4**: In experiment v4, we put all the training songs in the same key. The expectation is that the generated music sounds more harmonic and the input space is reduced. Contrary to our expectation, we need much more time for training. The result has also deteriorated significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Imports ##################\n",
    "from music21 import converter, instrument, note, chord, stream, tempo\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, CuDNNLSTM, Reshape\n",
    "from tqdm import tnrange\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Pre Processing ##################\n",
    "\n",
    "######### PARAMETERS #########\n",
    "# preprocessing\n",
    "music_directories = ('beeth', )\n",
    "sequence_length = 140\n",
    "\n",
    "# training\n",
    "training_epochs = 100\n",
    "training_batch_size = 1024\n",
    "\n",
    "# inference\n",
    "generated_notes_length = 300\n",
    "file_name = 'test_gen_beeth.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Pre Processing ##################\n",
    "######### FUNCTIONS #########\n",
    "\n",
    "# Load music file in given directories. Merge multiple hands and return music dictionary. This dictionary contains all notes for both hands at each global timestep\n",
    "def load_music(data_dirs):\n",
    "    music = {}\n",
    "    total_offset = 0\n",
    "    # load all files in all dirs\n",
    "    for path in data_dirs:\n",
    "        for file in glob.glob(path + '/*.mid'):\n",
    "            print('parsing file ' + file)\n",
    "            midi = converter.parse(file)\n",
    "            notes_to_parse = midi.recurse()\n",
    "            # falls mindestens 1 element in music, get totaloffset as biggest element of music\n",
    "            if len(music.keys()) > 0:\n",
    "                total_offset= sorted(music.keys())[-1]\n",
    "            #go through all nodes\n",
    "            for el in notes_to_parse:\n",
    "                #check if offset is defined as float already \n",
    "                offset = float(el.offset)\n",
    "                offset += total_offset\n",
    "                #check if offset already occured before, no merge both the part of left and right hand\n",
    "                if offset not in music:\n",
    "                    music[offset] = []\n",
    "                if isinstance(el, note.Note):\n",
    "                    music[offset].append(el)\n",
    "                elif isinstance(el, chord.Chord):\n",
    "                    for element in el.notes:\n",
    "                        music[offset].append(element)\n",
    "                else:\n",
    "                    if offset in music: del music[offset]\n",
    "    return music\n",
    "\n",
    "# If a given note (pitch) is flat, transform into sharp (requires flat_to_sharp mapping)\n",
    "def to_sharp(pitch):\n",
    "    # Mapping from flat to sharp notes in order to decrease dimensionality\n",
    "    flat_to_sharp={\n",
    "        'D-':'C#',\n",
    "        'E-':'D#',\n",
    "        'G-':'F#',\n",
    "        'A-':'G#',\n",
    "        'B-':'A#'\n",
    "    }\n",
    "    #pitch=e.g. 'E-4'\n",
    "    if pitch not in ['-1']:\n",
    "        if '-' in pitch:\n",
    "            #flat!\n",
    "            #get octave:\n",
    "            octave = pitch[-1]\n",
    "            return flat_to_sharp[pitch[:2]] + octave#0 to 1\n",
    "        else:\n",
    "            return pitch\n",
    "    else:\n",
    "        return pitch\n",
    "    \n",
    "#sort notes: 1. octave 2. pitch =>actual hight, not character\n",
    "def sort_notes(unique_note_freqs):\n",
    "#define all possible pitches\n",
    "    possible_pitches = ['C','C#','D','D#','E','F','F#','G', 'G#','A','A#','B']\n",
    "    all_pitches=[]\n",
    "    for i in range(0,8):#1 to 7\n",
    "        for pitch in possible_pitches:\n",
    "            all_pitches.append(pitch+str(i))\n",
    "    valid_pitches=[]\n",
    "    for all_pitch in all_pitches:\n",
    "        if all_pitch in unique_note_freqs:\n",
    "            valid_pitches.append(all_pitch)\n",
    "    return valid_pitches\n",
    "\n",
    "# Convert music dictionary to music list\n",
    "def music_dict_to_list(music_dict):\n",
    "    music_list=[]\n",
    "    for key in sorted(music_dict):\n",
    "        music_list.append([key, music_dict[key]])\n",
    "    return music_list\n",
    "\n",
    "# get unqiue list of notes from given music list\n",
    "def get_unique_notes(music_list):\n",
    "    unique_notes = []\n",
    "    for _, notes in music_list:\n",
    "        #for each note      \n",
    "        for _, current_note in enumerate(notes):\n",
    "            current_pitch = to_sharp(str(current_note.pitch))\n",
    "            #get all unique notes:\n",
    "            if current_pitch not in unique_notes:\n",
    "                unique_notes.append(current_pitch)\n",
    "    return unique_notes\n",
    "\n",
    "# get unique list of durations form given music list\n",
    "def get_unique_durations(music_list):\n",
    "    unique_durations = []\n",
    "    for _, notes in music_list:\n",
    "        #for each note      \n",
    "        for _, current_note in enumerate(notes):\n",
    "            current_duration = float(current_note.quarterLength)\n",
    "            #get all unique durations:\n",
    "            if current_duration not in unique_durations:\n",
    "                unique_durations.append(current_duration)\n",
    "    return unique_durations\n",
    "\n",
    "# get unique list of durations form given music list\n",
    "def get_unique_temporal_differences(music_list):\n",
    "    unique_temporal_differences = [0.0]\n",
    "    i = 0\n",
    "    for _, notes in music_list:\n",
    "        #define temporal difference\n",
    "        #temporal difference: time until next note in list\n",
    "        #e.g. if it's 0 it play simultaneously with next note\n",
    "        #check if next note at i+1 exists to calculate time until next note\n",
    "        if len(music_list) > i+1:\n",
    "            #temporal differnce = duration from current timestamp to next timestamp\n",
    "            temporal_difference = music_list[i+1][0] - music_list[i][0]\n",
    "        else:\n",
    "            #for last note\n",
    "            #temporal differnce = duration of note\n",
    "            temporal_difference = notes[0].quarterLength\n",
    "        if temporal_difference not in unique_temporal_differences:\n",
    "            unique_temporal_differences.append(temporal_difference)\n",
    "        i+=1\n",
    "    return unique_temporal_differences\n",
    "\n",
    "# transform a music list into training data. We select 3 features for each note.\n",
    "def create_training_data(music_list):\n",
    "    training_data = []\n",
    "    i=0\n",
    "    for timestamp, notes in music_list:\n",
    "        if len(music_list) > i+1:\n",
    "            #temporal differnce = duration from current timestamp to next timestamp\n",
    "            temporal_difference = music_list[i+1][0] - music_list[i][0]\n",
    "        else:\n",
    "            #for last note\n",
    "            #temporal differnce = duration of note\n",
    "            temporal_difference = notes[0].quarterLength\n",
    "        #for each note      \n",
    "        for idx, current_note in enumerate(notes):\n",
    "            current_pitch = to_sharp(str(current_note.pitch))#to_sharp translates notes with 2 names => reduce input space\n",
    "            current_duration = float(current_note.quarterLength)\n",
    "            #append to training_data \n",
    "            if (idx+1) == len(notes):\n",
    "                #last note in timestamp\n",
    "                training_data.append([temporal_difference, current_pitch, current_duration])\n",
    "            else:\n",
    "                #temporal difference of 0 for simultaneous notes\n",
    "                training_data.append([0, current_pitch, current_duration])\n",
    "        i += 1\n",
    "    return training_data\n",
    "\n",
    "# create training sequences and the correpsonding outputs for given training data\n",
    "def create_sequences(training_data, sequence_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(0, len(training_data) - sequence_length):\n",
    "        sequence_in = training_data[i:i + sequence_length]\n",
    "        sequence_out = training_data[i + sequence_length]\n",
    "        X.append(sequence_in)\n",
    "        y.append(sequence_out)\n",
    "    return X, y\n",
    "\n",
    "# normalize input sequences\n",
    "def normalize_input(X, unique_note_to_int, unique_duration_to_int, unique_temporal_difference_to_int):\n",
    "    normalized_X=[]\n",
    "    for sequence in X:\n",
    "        normalized_sequence_X = []\n",
    "        for data in sequence:\n",
    "            normalized_single_X=[]\n",
    "            # normalize temporal_diff:\n",
    "            normalized_single_X.append(unique_temporal_difference_to_int[data[0]]/len(unique_temporal_difference_to_int.keys()))\n",
    "            # normalize pitch\n",
    "            normalized_single_X.append(unique_note_to_int[data[1]]/len(unique_note_to_int.keys()))\n",
    "            # normalize duration\n",
    "            normalized_single_X.append(unique_duration_to_int[data[2]]/len(unique_duration_to_int.keys()))\n",
    "            # append normalized feature set to sequence\n",
    "            normalized_sequence_X.append(normalized_single_X)\n",
    "        normalized_X.append(normalized_sequence_X)\n",
    "    return normalized_X\n",
    "\n",
    "# normalize output feature set\n",
    "def normalize_output(y, unique_note_to_int, unique_duration_to_int, unique_temporal_difference_to_int):\n",
    "    normalized_y = []\n",
    "    for data in y:\n",
    "        normalized_single_y=[]\n",
    "        # normalize temporal_diff:\n",
    "        normalized_single_y.append(unique_temporal_difference_to_int[data[0]])\n",
    "        # normalize pitch\n",
    "        normalized_single_y.append(unique_note_to_int[data[1]])\n",
    "        # normalize duration\n",
    "        normalized_single_y.append(unique_duration_to_int[data[2]])\n",
    "        # append normalized feature set to y\n",
    "        normalized_y.append(normalized_single_y)\n",
    "    normalized_y = to_categorical(normalized_y)\n",
    "    return normalized_y\n",
    "\n",
    "# predict output feature sets with trained model\n",
    "def predict_notes(model, pattern, generated_notes_length, unique_temporal_differences_length, unique_notes_length, unique_durations_length):\n",
    "    prediction_output = []\n",
    "    for note_index in tnrange(generated_notes_length, desc='generating notes'):\n",
    "        # predict next feature set with given pattern\n",
    "        prediction_input = np.reshape(pattern, (1, pattern.shape[0], pattern.shape[1]))\n",
    "        \n",
    "        #print(\"prediction input:\\n\",prediction_input)\n",
    "        \n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "        \n",
    "        # get max predictions\n",
    "        index_temporal_difference = np.argmax(prediction[0][0])\n",
    "        index_note = np.argmax(prediction[0][1])\n",
    "        index_duration = np.argmax(prediction[0][2])\n",
    "        \n",
    "        #print(\"prediction 0\", prediction[0][0])\n",
    "        #print(\"prediction 1\", prediction[0][1])\n",
    "        #print(\"prediction 2\", prediction[0][2])\n",
    "        \n",
    "        #print(\"prediction index 0\", index_temporal_difference)\n",
    "        #print(\"prediction index 1\", index_note)\n",
    "        #print(\"prediction index 2\", index_duration)\n",
    "\n",
    "        # transform prediction at max index\n",
    "        result_temporal_difference = int_to_unique_temporal_difference[index_temporal_difference]\n",
    "        result_note = int_to_unique_note[index_note]\n",
    "        result_duration = int_to_unique_duration[index_duration]\n",
    "        \n",
    "        # Normalize predictions to append it to the sequence\n",
    "        result_temporal_difference_normalized = index_temporal_difference/unique_temporal_differences_length\n",
    "        result_note_normalized = index_note/unique_notes_length\n",
    "        result_duration_normalized = index_duration/unique_durations_length\n",
    "        \n",
    "        #print(\"result 0\", result_temporal_difference)\n",
    "        #print(\"result 1\", result_note)\n",
    "        #print(\"result 2\", result_duration)\n",
    "\n",
    "        # append result to output\n",
    "        prediction_output.append([result_temporal_difference, result_note, result_duration])\n",
    "        \n",
    "        # add new pattern in order to generate next feature set\n",
    "        #pattern = np.vstack((pattern, (result_temporal_difference,result_note_normalized,result_duration)))\n",
    "        pattern = np.vstack((pattern, (result_temporal_difference_normalized,result_note_normalized,result_duration_normalized)))\n",
    "        pattern = np.delete(pattern, 0, 0)\n",
    "    return prediction_output\n",
    "\n",
    "# convert \n",
    "def convert_musiclist_to_music(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for feature_set in prediction_output:  \n",
    "        # get single values from generated feature set\n",
    "        gen_offset = feature_set[0]\n",
    "        gen_note = feature_set[1]\n",
    "        gen_duration = feature_set[2]\n",
    "\n",
    "        # create note\n",
    "        new_note = note.Note(gen_note, quarterLength=gen_duration)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration\n",
    "        offset += gen_offset\n",
    "    return output_notes\n",
    "\n",
    "# play generated music\n",
    "def play_music(output_notes, file_name):\n",
    "    midi_stream = stream.Stream(output_notes) #output_notes\n",
    "    #mm1 = tempo.MetronomeMark('slow')\n",
    "    #midi_stream.append(mm1)\n",
    "    #midi_stream.append(output_notes)\n",
    "    midi_stream.write('midi', fp=file_name)\n",
    "    midi_stream.show('midi')\n",
    "    #midi_stream.show('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing file beeth/mond_3.mid\n",
      "parsing file beeth/beethoven_opus10_3.mid\n",
      "parsing file beeth/beethoven_opus22_3.mid\n",
      "parsing file beeth/pathetique_2.mid\n",
      "parsing file beeth/waldstein_2.mid\n",
      "parsing file beeth/beethoven_opus90_2.mid\n",
      "parsing file beeth/beethoven_hammerklavier_4.mid\n",
      "parsing file beeth/appass_2.mid\n",
      "parsing file beeth/beethoven_hammerklavier_3.mid\n",
      "parsing file beeth/waldstein_1.mid\n",
      "parsing file beeth/beethoven_les_adieux_1.mid\n",
      "parsing file beeth/appass_1.mid\n",
      "parsing file beeth/beethoven_opus10_1.mid\n",
      "parsing file beeth/beethoven_opus22_2.mid\n",
      "parsing file beeth/beethoven_hammerklavier_1.mid\n",
      "parsing file beeth/appass_3.mid\n",
      "parsing file beeth/beethoven_opus90_1.mid\n",
      "parsing file beeth/elise.mid\n",
      "parsing file beeth/pathetique_1.mid\n",
      "parsing file beeth/beethoven_hammerklavier_2.mid\n",
      "parsing file beeth/beethoven_opus22_4.mid\n",
      "parsing file beeth/pathetique_3.mid\n",
      "parsing file beeth/mond_1.mid\n",
      "parsing file beeth/beethoven_les_adieux_3.mid\n",
      "parsing file beeth/beethoven_les_adieux_2.mid\n",
      "parsing file beeth/mond_2.mid\n",
      "parsing file beeth/waldstein_3.mid\n",
      "parsing file beeth/beethoven_opus22_1.mid\n",
      "parsing file beeth/beethoven_opus10_2.mid\n",
      "# Parsed music length: 52303\n",
      "# Unique notes:\n",
      " ['C1', 'C#1', 'D1', 'D#1', 'E1', 'F1', 'F#1', 'G1', 'G#1', 'A1', 'A#1', 'B1', 'C2', 'C#2', 'D2', 'D#2', 'E2', 'F2', 'F#2', 'G2', 'G#2', 'A2', 'A#2', 'B2', 'C3', 'C#3', 'D3', 'D#3', 'E3', 'F3', 'F#3', 'G3', 'G#3', 'A3', 'A#3', 'B3', 'C4', 'C#4', 'D4', 'D#4', 'E4', 'F4', 'F#4', 'G4', 'G#4', 'A4', 'A#4', 'B4', 'C5', 'C#5', 'D5', 'D#5', 'E5', 'F5', 'F#5', 'G5', 'G#5', 'A5', 'A#5', 'B5', 'C6', 'C#6', 'D6', 'D#6', 'E6', 'F6', 'F#6', 'G6', 'G#6', 'A6', 'A#6', 'B6', 'C7', 'C#7', 'D7', 'D#7', 'E7', 'F7']\n",
      "# Unique durations: [0.25, 1.0, 0.0, 0.5, 8.0, 0.75, 2.0, 7.5, 1.5, 2.25, 3.0, 1.75, 1.6666666666666667, 1.3333333333333333, 1.25, 3.5, 3.3333333333333335, 3.25, 3.75, 0.3333333333333333, 5.333333333333333, 5.0, 4.0, 0.6666666666666666, 2.5, 7.333333333333333, 7.0, 6.666666666666667, 6.333333333333333, 2.6666666666666665, 2.3333333333333335, 4.25, 4.5, 2.75, 9.0, 6.0, 11.75, 12.0, 3.6666666666666665]\n",
      "# Max duration: 12.0\n",
      "# Unique temporal differences [0.0, 0.25, 0.5, 0.75, 1.0, 3.0, 0.0833333333333286, 0.1666666666666714, 2.25, 0.08333333333334281, 0.1666666666666572, 1.25, 0.08333333333331439, 0.16666666666668561, 4.0, 0.08333333333337123, 0.16666666666662877, 0.33333333333337123, 3.5, 0.33333333333325754, 0.5833333333333712, 0.41666666666662877, 2.5, 1.5833333333333712, 3.3333333333333712, 2.6666666666666288, 7.333333333333371, 2.0, 1.5, 0.16666666666674246, 0.08333333333325754, 0.3333333333334849, 0.6666666666665151, 5.5, 2.75, 0.33333333333303017, 0.6666666666669698, 0.16666666666651508, 0.08333333333348492, 5.0, 3.25, 4.25, 2.083333333333485, 1.083333333333485, 0.5833333333334849, 0.4166666666665151, 1.75, 1.666666666666515, 2.33333333333303, 1.333333333333485, 0.8333333333334849, 1.166666666666515, 8.0, 0.08333333333303017, 0.16666666666696983, 0.33333333333393966, 1.5833333333330302, 1.1666666666669698, 1.3333333333330302, 0.5833333333330302, 1.6666666666660603, 1.6666666666669698, 0.41666666666696983, 0.6666666666660603, 7.0, 7.5, 6.5, 4.5, 6.0, 0.8333333333330302, 5.75, 18.5, 4.75, 3.75, 0.3333333333321207, 4.33333333333394, 0.16666666666606034, 0.08333333333393966, 3.8333333333339397, 0.41666666666606034, 0.5833333333339397, 1.3333333333339397, 0.9166666666660603, 3.3333333333339397, 3.6666666666660603, 1.5833333333339397, 5.25, 0.8333333333339397, 0.6666666666678793, 2.3333333333339397, 1.6666666666678793, 6.33333333333394, 6.25, 0.08333333333212067, 0.16666666666787933, 0.5833333333321207, 0.4166666666678793, 0.33333333333575865, 7.25, 3.6666666666678793, 2.6666666666678793, 1.3333333333321207, 0.6666666666642413, 2.3333333333321207, 1.0833333333321207]\n",
      "# Max temporal difference: 18.5\n",
      "# First element of training data (temporal_difference, note, duration):\n",
      " [0.25, 'G#2', 0.25]\n",
      "# Unique note to int:\n",
      " {'C1': 0, 'C#1': 1, 'D1': 2, 'D#1': 3, 'E1': 4, 'F1': 5, 'F#1': 6, 'G1': 7, 'G#1': 8, 'A1': 9, 'A#1': 10, 'B1': 11, 'C2': 12, 'C#2': 13, 'D2': 14, 'D#2': 15, 'E2': 16, 'F2': 17, 'F#2': 18, 'G2': 19, 'G#2': 20, 'A2': 21, 'A#2': 22, 'B2': 23, 'C3': 24, 'C#3': 25, 'D3': 26, 'D#3': 27, 'E3': 28, 'F3': 29, 'F#3': 30, 'G3': 31, 'G#3': 32, 'A3': 33, 'A#3': 34, 'B3': 35, 'C4': 36, 'C#4': 37, 'D4': 38, 'D#4': 39, 'E4': 40, 'F4': 41, 'F#4': 42, 'G4': 43, 'G#4': 44, 'A4': 45, 'A#4': 46, 'B4': 47, 'C5': 48, 'C#5': 49, 'D5': 50, 'D#5': 51, 'E5': 52, 'F5': 53, 'F#5': 54, 'G5': 55, 'G#5': 56, 'A5': 57, 'A#5': 58, 'B5': 59, 'C6': 60, 'C#6': 61, 'D6': 62, 'D#6': 63, 'E6': 64, 'F6': 65, 'F#6': 66, 'G6': 67, 'G#6': 68, 'A6': 69, 'A#6': 70, 'B6': 71, 'C7': 72, 'C#7': 73, 'D7': 74, 'D#7': 75, 'E7': 76, 'F7': 77}\n",
      "# Int to unique note:\n",
      " {0: 'C1', 1: 'C#1', 2: 'D1', 3: 'D#1', 4: 'E1', 5: 'F1', 6: 'F#1', 7: 'G1', 8: 'G#1', 9: 'A1', 10: 'A#1', 11: 'B1', 12: 'C2', 13: 'C#2', 14: 'D2', 15: 'D#2', 16: 'E2', 17: 'F2', 18: 'F#2', 19: 'G2', 20: 'G#2', 21: 'A2', 22: 'A#2', 23: 'B2', 24: 'C3', 25: 'C#3', 26: 'D3', 27: 'D#3', 28: 'E3', 29: 'F3', 30: 'F#3', 31: 'G3', 32: 'G#3', 33: 'A3', 34: 'A#3', 35: 'B3', 36: 'C4', 37: 'C#4', 38: 'D4', 39: 'D#4', 40: 'E4', 41: 'F4', 42: 'F#4', 43: 'G4', 44: 'G#4', 45: 'A4', 46: 'A#4', 47: 'B4', 48: 'C5', 49: 'C#5', 50: 'D5', 51: 'D#5', 52: 'E5', 53: 'F5', 54: 'F#5', 55: 'G5', 56: 'G#5', 57: 'A5', 58: 'A#5', 59: 'B5', 60: 'C6', 61: 'C#6', 62: 'D6', 63: 'D#6', 64: 'E6', 65: 'F6', 66: 'F#6', 67: 'G6', 68: 'G#6', 69: 'A6', 70: 'A#6', 71: 'B6', 72: 'C7', 73: 'C#7', 74: 'D7', 75: 'D#7', 76: 'E7', 77: 'F7'}\n",
      "# Unique duration to int:\n",
      " {0.25: 0, 1.0: 1, 0.0: 2, 0.5: 3, 8.0: 4, 0.75: 5, 2.0: 6, 7.5: 7, 1.5: 8, 2.25: 9, 3.0: 10, 1.75: 11, 1.6666666666666667: 12, 1.3333333333333333: 13, 1.25: 14, 3.5: 15, 3.3333333333333335: 16, 3.25: 17, 3.75: 18, 0.3333333333333333: 19, 5.333333333333333: 20, 5.0: 21, 4.0: 22, 0.6666666666666666: 23, 2.5: 24, 7.333333333333333: 25, 7.0: 26, 6.666666666666667: 27, 6.333333333333333: 28, 2.6666666666666665: 29, 2.3333333333333335: 30, 4.25: 31, 4.5: 32, 2.75: 33, 9.0: 34, 6.0: 35, 11.75: 36, 12.0: 37, 3.6666666666666665: 38}\n",
      "# Int to unique duration:\n",
      " {0: 0.25, 1: 1.0, 2: 0.0, 3: 0.5, 4: 8.0, 5: 0.75, 6: 2.0, 7: 7.5, 8: 1.5, 9: 2.25, 10: 3.0, 11: 1.75, 12: 1.6666666666666667, 13: 1.3333333333333333, 14: 1.25, 15: 3.5, 16: 3.3333333333333335, 17: 3.25, 18: 3.75, 19: 0.3333333333333333, 20: 5.333333333333333, 21: 5.0, 22: 4.0, 23: 0.6666666666666666, 24: 2.5, 25: 7.333333333333333, 26: 7.0, 27: 6.666666666666667, 28: 6.333333333333333, 29: 2.6666666666666665, 30: 2.3333333333333335, 31: 4.25, 32: 4.5, 33: 2.75, 34: 9.0, 35: 6.0, 36: 11.75, 37: 12.0, 38: 3.6666666666666665}\n",
      "# Unique temporal difference to int:\n",
      " {0.0: 0, 0.25: 1, 0.5: 2, 0.75: 3, 1.0: 4, 3.0: 5, 0.0833333333333286: 6, 0.1666666666666714: 7, 2.25: 8, 0.08333333333334281: 9, 0.1666666666666572: 10, 1.25: 11, 0.08333333333331439: 12, 0.16666666666668561: 13, 4.0: 14, 0.08333333333337123: 15, 0.16666666666662877: 16, 0.33333333333337123: 17, 3.5: 18, 0.33333333333325754: 19, 0.5833333333333712: 20, 0.41666666666662877: 21, 2.5: 22, 1.5833333333333712: 23, 3.3333333333333712: 24, 2.6666666666666288: 25, 7.333333333333371: 26, 2.0: 27, 1.5: 28, 0.16666666666674246: 29, 0.08333333333325754: 30, 0.3333333333334849: 31, 0.6666666666665151: 32, 5.5: 33, 2.75: 34, 0.33333333333303017: 35, 0.6666666666669698: 36, 0.16666666666651508: 37, 0.08333333333348492: 38, 5.0: 39, 3.25: 40, 4.25: 41, 2.083333333333485: 42, 1.083333333333485: 43, 0.5833333333334849: 44, 0.4166666666665151: 45, 1.75: 46, 1.666666666666515: 47, 2.33333333333303: 48, 1.333333333333485: 49, 0.8333333333334849: 50, 1.166666666666515: 51, 8.0: 52, 0.08333333333303017: 53, 0.16666666666696983: 54, 0.33333333333393966: 55, 1.5833333333330302: 56, 1.1666666666669698: 57, 1.3333333333330302: 58, 0.5833333333330302: 59, 1.6666666666660603: 60, 1.6666666666669698: 61, 0.41666666666696983: 62, 0.6666666666660603: 63, 7.0: 64, 7.5: 65, 6.5: 66, 4.5: 67, 6.0: 68, 0.8333333333330302: 69, 5.75: 70, 18.5: 71, 4.75: 72, 3.75: 73, 0.3333333333321207: 74, 4.33333333333394: 75, 0.16666666666606034: 76, 0.08333333333393966: 77, 3.8333333333339397: 78, 0.41666666666606034: 79, 0.5833333333339397: 80, 1.3333333333339397: 81, 0.9166666666660603: 82, 3.3333333333339397: 83, 3.6666666666660603: 84, 1.5833333333339397: 85, 5.25: 86, 0.8333333333339397: 87, 0.6666666666678793: 88, 2.3333333333339397: 89, 1.6666666666678793: 90, 6.33333333333394: 91, 6.25: 92, 0.08333333333212067: 93, 0.16666666666787933: 94, 0.5833333333321207: 95, 0.4166666666678793: 96, 0.33333333333575865: 97, 7.25: 98, 3.6666666666678793: 99, 2.6666666666678793: 100, 1.3333333333321207: 101, 0.6666666666642413: 102, 2.3333333333321207: 103, 1.0833333333321207: 104}\n",
      "# Int to unique temporal difference:\n",
      " {0: 0.0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1.0, 5: 3.0, 6: 0.0833333333333286, 7: 0.1666666666666714, 8: 2.25, 9: 0.08333333333334281, 10: 0.1666666666666572, 11: 1.25, 12: 0.08333333333331439, 13: 0.16666666666668561, 14: 4.0, 15: 0.08333333333337123, 16: 0.16666666666662877, 17: 0.33333333333337123, 18: 3.5, 19: 0.33333333333325754, 20: 0.5833333333333712, 21: 0.41666666666662877, 22: 2.5, 23: 1.5833333333333712, 24: 3.3333333333333712, 25: 2.6666666666666288, 26: 7.333333333333371, 27: 2.0, 28: 1.5, 29: 0.16666666666674246, 30: 0.08333333333325754, 31: 0.3333333333334849, 32: 0.6666666666665151, 33: 5.5, 34: 2.75, 35: 0.33333333333303017, 36: 0.6666666666669698, 37: 0.16666666666651508, 38: 0.08333333333348492, 39: 5.0, 40: 3.25, 41: 4.25, 42: 2.083333333333485, 43: 1.083333333333485, 44: 0.5833333333334849, 45: 0.4166666666665151, 46: 1.75, 47: 1.666666666666515, 48: 2.33333333333303, 49: 1.333333333333485, 50: 0.8333333333334849, 51: 1.166666666666515, 52: 8.0, 53: 0.08333333333303017, 54: 0.16666666666696983, 55: 0.33333333333393966, 56: 1.5833333333330302, 57: 1.1666666666669698, 58: 1.3333333333330302, 59: 0.5833333333330302, 60: 1.6666666666660603, 61: 1.6666666666669698, 62: 0.41666666666696983, 63: 0.6666666666660603, 64: 7.0, 65: 7.5, 66: 6.5, 67: 4.5, 68: 6.0, 69: 0.8333333333330302, 70: 5.75, 71: 18.5, 72: 4.75, 73: 3.75, 74: 0.3333333333321207, 75: 4.33333333333394, 76: 0.16666666666606034, 77: 0.08333333333393966, 78: 3.8333333333339397, 79: 0.41666666666606034, 80: 0.5833333333339397, 81: 1.3333333333339397, 82: 0.9166666666660603, 83: 3.3333333333339397, 84: 3.6666666666660603, 85: 1.5833333333339397, 86: 5.25, 87: 0.8333333333339397, 88: 0.6666666666678793, 89: 2.3333333333339397, 90: 1.6666666666678793, 91: 6.33333333333394, 92: 6.25, 93: 0.08333333333212067, 94: 0.16666666666787933, 95: 0.5833333333321207, 96: 0.4166666666678793, 97: 0.33333333333575865, 98: 7.25, 99: 3.6666666666678793, 100: 2.6666666666678793, 101: 1.3333333333321207, 102: 0.6666666666642413, 103: 2.3333333333321207, 104: 1.0833333333321207}\n",
      "# First X\n",
      " [[0.25, 'G#2', 0.25], [0, 'C#3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'E3', 0.25], [0, 'G#3', 0.25], [0.25, 'C#2', 0.25], [0.25, 'C#3', 0.25], [0, 'E3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#3', 0.25], [0, 'C#4', 0.25], [0.25, 'C#2', 0.25], [0.25, 'E3', 0.25], [0, 'G#3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'C#4', 0.25], [0, 'E4', 0.25], [0.25, 'C#2', 0.25], [0.25, 'G#3', 0.25], [0, 'C#4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'E4', 0.25], [0, 'G#4', 0.25], [0.25, 'C#2', 0.25], [0.25, 'C#4', 0.25], [0, 'E4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#4', 0.25], [0, 'C#5', 0.25], [0.25, 'C#2', 0.25], [0.25, 'E4', 0.25], [0, 'G#4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'C#5', 0.25], [0, 'E5', 0.25], [0.25, 'C#2', 0.25], [0.25, 'G#4', 0.25], [0, 'C#5', 0.25], [0.25, 'G#2', 0.25], [0.25, 'E5', 0.25], [0, 'C#3', 1.0], [0.5, 'C#2', 1.0], [0, 'G#4', 1.0], [0, 'C#5', 1.0], [0, 'G#5', 1.0], [0, 'E5', 1.0], [0.5, 'G#2', 0.25], [0.25, 'C2', 0.25], [0.25, 'G#2', 0.25], [0, 'C3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'D#3', 0.25], [0, 'G#3', 0.25], [0.25, 'C2', 0.25], [0.25, 'C3', 0.25], [0, 'D#3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#3', 0.25], [0, 'C4', 0.25], [0.25, 'C2', 0.25], [0.25, 'D#3', 0.25], [0, 'G#3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'C4', 0.25], [0, 'D#4', 0.25], [0.25, 'C2', 0.25], [0.25, 'G#3', 0.25], [0, 'C4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'D#4', 0.25], [0, 'G#4', 0.25], [0.25, 'C2', 0.25], [0.25, 'C4', 0.25], [0, 'D#4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#4', 0.25], [0, 'C5', 0.25], [0.25, 'C2', 0.25], [0.25, 'D#4', 0.25], [0, 'G#4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'C5', 0.25], [0, 'D#5', 0.25], [0.25, 'C2', 0.25], [0.25, 'G#4', 0.25], [0, 'C5', 0.25], [0.25, 'G#2', 0.25], [0.25, 'D#5', 0.25], [0, 'C3', 1.0], [0.5, 'C2', 1.0], [0, 'C5', 1.0], [0, 'G#5', 1.0], [0, 'G#4', 1.0], [0, 'D#5', 1.0], [0.5, 'G#2', 0.25], [0.25, 'B1', 0.25], [0.25, 'C#3', 0.25], [0, 'F3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#3', 0.25], [0, 'C#4', 0.25], [0.25, 'B1', 0.25], [0.25, 'F3', 0.25], [0, 'G#3', 0.25], [0.25, 'G#2', 0.25], [0.25, 'C#4', 0.25], [0, 'F4', 0.25], [0.25, 'B1', 0.25], [0.25, 'G#3', 0.25], [0, 'C#4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'F4', 0.25], [0, 'G#4', 0.25], [0.25, 'B1', 0.25], [0.25, 'C#4', 0.25], [0, 'F4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#4', 0.25], [0, 'C#5', 0.25], [0.25, 'B1', 0.25], [0.25, 'F4', 0.25], [0, 'G#4', 0.25], [0.25, 'G#2', 0.25], [0.25, 'C#5', 0.25], [0, 'F5', 0.25], [0.25, 'B1', 0.25], [0.25, 'G#4', 0.25], [0, 'C#5', 0.25], [0.25, 'G#2', 0.25], [0.25, 'F5', 0.25], [0, 'G#5', 0.25], [0.25, 'B1', 0.25], [0.25, 'C#5', 0.25], [0, 'F5', 0.25], [0.25, 'G#2', 0.25], [0.25, 'G#5', 0.25], [0, 'B1', 1.0], [0.5, 'B2', 1.0], [0, 'G#5', 1.0], [0, 'C#6', 1.0]]\n",
      "# First y\n",
      ": [0, 'C#5', 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# First normalized X\n",
      " [[0.009523809523809525, 0.2564102564102564, 0.0], [0.0, 0.32051282051282054, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.358974358974359, 0.0], [0.0, 0.41025641025641024, 0.0], [0.009523809523809525, 0.16666666666666666, 0.0], [0.009523809523809525, 0.32051282051282054, 0.0], [0.0, 0.358974358974359, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.41025641025641024, 0.0], [0.0, 0.47435897435897434, 0.0], [0.009523809523809525, 0.16666666666666666, 0.0], [0.009523809523809525, 0.358974358974359, 0.0], [0.0, 0.41025641025641024, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.47435897435897434, 0.0], [0.0, 0.5128205128205128, 0.0], [0.009523809523809525, 0.16666666666666666, 0.0], [0.009523809523809525, 0.41025641025641024, 0.0], [0.0, 0.47435897435897434, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.5128205128205128, 0.0], [0.0, 0.5641025641025641, 0.0], [0.009523809523809525, 0.16666666666666666, 0.0], [0.009523809523809525, 0.47435897435897434, 0.0], [0.0, 0.5128205128205128, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.5641025641025641, 0.0], [0.0, 0.6282051282051282, 0.0], [0.009523809523809525, 0.16666666666666666, 0.0], [0.009523809523809525, 0.5128205128205128, 0.0], [0.0, 0.5641025641025641, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.6282051282051282, 0.0], [0.0, 0.6666666666666666, 0.0], [0.009523809523809525, 0.16666666666666666, 0.0], [0.009523809523809525, 0.5641025641025641, 0.0], [0.0, 0.6282051282051282, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.6666666666666666, 0.0], [0.0, 0.32051282051282054, 0.02564102564102564], [0.01904761904761905, 0.16666666666666666, 0.02564102564102564], [0.0, 0.5641025641025641, 0.02564102564102564], [0.0, 0.6282051282051282, 0.02564102564102564], [0.0, 0.717948717948718, 0.02564102564102564], [0.0, 0.6666666666666666, 0.02564102564102564], [0.01904761904761905, 0.2564102564102564, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.0, 0.3076923076923077, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.34615384615384615, 0.0], [0.0, 0.41025641025641024, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.3076923076923077, 0.0], [0.0, 0.34615384615384615, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.41025641025641024, 0.0], [0.0, 0.46153846153846156, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.34615384615384615, 0.0], [0.0, 0.41025641025641024, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.46153846153846156, 0.0], [0.0, 0.5, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.41025641025641024, 0.0], [0.0, 0.46153846153846156, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.5, 0.0], [0.0, 0.5641025641025641, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.46153846153846156, 0.0], [0.0, 0.5, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.5641025641025641, 0.0], [0.0, 0.6153846153846154, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.5, 0.0], [0.0, 0.5641025641025641, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.6153846153846154, 0.0], [0.0, 0.6538461538461539, 0.0], [0.009523809523809525, 0.15384615384615385, 0.0], [0.009523809523809525, 0.5641025641025641, 0.0], [0.0, 0.6153846153846154, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.6538461538461539, 0.0], [0.0, 0.3076923076923077, 0.02564102564102564], [0.01904761904761905, 0.15384615384615385, 0.02564102564102564], [0.0, 0.6153846153846154, 0.02564102564102564], [0.0, 0.717948717948718, 0.02564102564102564], [0.0, 0.5641025641025641, 0.02564102564102564], [0.0, 0.6538461538461539, 0.02564102564102564], [0.01904761904761905, 0.2564102564102564, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.32051282051282054, 0.0], [0.0, 0.3717948717948718, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.41025641025641024, 0.0], [0.0, 0.47435897435897434, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.3717948717948718, 0.0], [0.0, 0.41025641025641024, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.47435897435897434, 0.0], [0.0, 0.5256410256410257, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.41025641025641024, 0.0], [0.0, 0.47435897435897434, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.5256410256410257, 0.0], [0.0, 0.5641025641025641, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.47435897435897434, 0.0], [0.0, 0.5256410256410257, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.5641025641025641, 0.0], [0.0, 0.6282051282051282, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.5256410256410257, 0.0], [0.0, 0.5641025641025641, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.6282051282051282, 0.0], [0.0, 0.6794871794871795, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.5641025641025641, 0.0], [0.0, 0.6282051282051282, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.6794871794871795, 0.0], [0.0, 0.717948717948718, 0.0], [0.009523809523809525, 0.14102564102564102, 0.0], [0.009523809523809525, 0.6282051282051282, 0.0], [0.0, 0.6794871794871795, 0.0], [0.009523809523809525, 0.2564102564102564, 0.0], [0.009523809523809525, 0.717948717948718, 0.0], [0.0, 0.14102564102564102, 0.02564102564102564], [0.01904761904761905, 0.2948717948717949, 0.02564102564102564], [0.0, 0.717948717948718, 0.02564102564102564], [0.0, 0.782051282051282, 0.02564102564102564]]\n",
      "# First normalized y\n",
      ": [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "# Shape of X (after reshape): (82460, 140, 3)\n",
      "# Shape of y (after reshape): (82460, 3, 105)\n"
     ]
    }
   ],
   "source": [
    "################## Pre Processing ##################\n",
    "######### LOGIC #########\n",
    "\n",
    "# load music files\n",
    "music = load_music(data_dirs=music_directories)\n",
    "print(\"# Parsed music length:\",len(music))\n",
    "\n",
    "# convert music dictionary to list\n",
    "music_list = music_dict_to_list(music)\n",
    "\n",
    "# get unique notes from music list\n",
    "unique_notes = get_unique_notes(music_list)\n",
    "#sort unique notes by actual pitch\n",
    "unique_notes = sort_notes(unique_notes)\n",
    "print(\"# Unique notes:\\n\", unique_notes)\n",
    "\n",
    "# get unique durations from music list \n",
    "unique_durations = get_unique_durations(music_list)\n",
    "print(\"# Unique durations:\", unique_durations)\n",
    "# get max duration from music list\n",
    "max_duration = max(unique_durations)\n",
    "print(\"# Max duration:\", max_duration)\n",
    "\n",
    "# get unqiue temporal difference\n",
    "unique_temporal_differences = get_unique_temporal_differences(music_list)\n",
    "print(\"# Unique temporal differences\", unique_temporal_differences)\n",
    "# get max temporal difference\n",
    "max_temporal_difference = max(unique_temporal_differences)\n",
    "print(\"# Max temporal difference:\", max_temporal_difference)\n",
    "\n",
    "# create training data by extracting 3 required features for each note\n",
    "training_data = create_training_data(music_list)\n",
    "print(\"# First element of training data (temporal_difference, note, duration):\\n\",training_data[0])\n",
    "\n",
    "## create Mappings for all features\n",
    "# create a dictionary to map notes to integers\n",
    "unique_note_to_int = {note: number for number, note in enumerate(unique_notes)}\n",
    "print(\"# Unique note to int:\\n\", unique_note_to_int)\n",
    "int_to_unique_note = {number: note for number, note in enumerate(unique_notes)}\n",
    "print(\"# Int to unique note:\\n\", int_to_unique_note)\n",
    "\n",
    "# create a dictionary to map durations to integers\n",
    "unique_duration_to_int = {duration: number for number, duration in enumerate(unique_durations)}\n",
    "print(\"# Unique duration to int:\\n\", unique_duration_to_int)\n",
    "int_to_unique_duration = {number: duration for number, duration in enumerate(unique_durations)}\n",
    "print(\"# Int to unique duration:\\n\", int_to_unique_duration)\n",
    "\n",
    "# create a dictionary to map temporal differences to integers\n",
    "unique_temporal_difference_to_int = {temporal_difference: number for number, temporal_difference in enumerate(unique_temporal_differences)}\n",
    "print(\"# Unique temporal difference to int:\\n\", unique_temporal_difference_to_int)\n",
    "int_to_unique_temporal_difference = {number: temporal_difference for number, temporal_difference in enumerate(unique_temporal_differences)}\n",
    "print(\"# Int to unique temporal difference:\\n\", int_to_unique_temporal_difference)\n",
    "\n",
    "# create input sequences and the corresponding outputs\n",
    "X, y = create_sequences(training_data, sequence_length)\n",
    "print(\"# First X\\n\", X[0])\n",
    "print(\"# First y\\n:\", y[0])\n",
    "\n",
    "# normalize input and output\n",
    "X = normalize_input(X, unique_note_to_int, unique_duration_to_int, unique_temporal_difference_to_int)\n",
    "y = normalize_output(y, unique_note_to_int, unique_duration_to_int, unique_temporal_difference_to_int)\n",
    "print(\"# First normalized X\\n\", X[0])\n",
    "print(\"# First normalized y\\n:\", y[0])\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "X = np.reshape(X, (-1, sequence_length, 3))\n",
    "print(\"# Shape of X (after reshape):\", X.shape)\n",
    "print(\"# Shape of y (after reshape):\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pia3/.direnv/python-3.7.3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/pia3/.direnv/python-3.7.3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 140, 1024)         4214784   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 140, 1024)         0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 140, 1024)         8396800   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 140, 1024)         0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 512)               3149824   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 315)               161595    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 3, 105)            0         \n",
      "=================================================================\n",
      "Total params: 15,923,003\n",
      "Trainable params: 15,923,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "################## Model ##################\n",
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(\n",
    "    1024,\n",
    "    return_sequences=True, \n",
    "    input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(CuDNNLSTM(1024, return_sequences=True))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(CuDNNLSTM(512))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=y.shape[1] * y.shape[2], activation='softmax'))\n",
    "model.add(Reshape((y.shape[1] ,y.shape[2])))\n",
    "model.load_weights('results_RNN/v1/newchpts_beeth_950e')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncheckpoint = ModelCheckpoint(\\n    'newchpts',\\n    monitor='loss',\\n    verbose=0,\\n    save_best_only=True,\\n    mode='min'\\n)\\n\\ncallbacks_list = [checkpoint]\\nmodel.fit(X, y, epochs=training_epochs, batch_size=training_batch_size, callbacks=callbacks_list)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## Training ##################\n",
    "# Wir laden bereits trainierte Gewichte, daher ist das trainig auskommentiert.\n",
    "\"\"\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'newchpts',\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X, y, epochs=training_epochs, batch_size=training_batch_size, callbacks=callbacks_list)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d7650bf6064cf4bd73482e85bec60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='generating notes', max=300, style=ProgressStyle(description_w"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv147219'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv147219');\n",
       "                               mp.base64Load('data:audio/midi;base64,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');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################## Inference ##################\n",
    "\n",
    "# get random notes from training data\n",
    "start = np.random.randint(0, len(X)-1)\n",
    "seed = X[start]\n",
    "# predict model output of specified length, starting with the previously created seed\n",
    "prediction_output = predict_notes(model, seed, generated_notes_length, len(unique_temporal_differences), len(unique_notes), len(unique_durations)) \n",
    "\n",
    "# Convert feature set back to music\n",
    "output_notes = convert_musiclist_to_music(prediction_output)\n",
    "\n",
    "# Finally: Play music!\n",
    "play_music(output_notes, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "\n",
    "Ideas for the future ;)\n",
    "\n",
    "## Separate models for note, duration and temporal difference.\n",
    "\n",
    "Three models are learned. All models get the same input (sequences consisting of note, duration and temporal difference).\n",
    "Each model provides the output for one of the 3 features. The individual features are then memorized for generation and can be played back as midi. Each model therefore focuses on the generation of a specific feature.\n",
    "\n",
    "## Feed music separately\n",
    "\n",
    "The individual music features probably do not fit together. It is very likely that the individual sequences overlap during training. Thus, the network learns with notes that do not match.\n",
    "One idea to solve this problem is to train the net with the different pieces of music one after the other. A loop that trains the network for each file in a folder a few epochs at a time would be conceivable.\n",
    "\n",
    "## Separate music\n",
    "Another way to solve the problem described before would be to extend the music to separate them. This could be done by inserting long pauses after each track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
